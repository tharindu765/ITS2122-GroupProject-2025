{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5403cd9b",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# ITS 2122: Python for Data Science & AI - Group Project\n",
    "# Strategic Growth Analysis for a UK-Based E-Commerce Retailer\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376e605",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This notebook presents a comprehensive analysis of \"Unique Gifts Ltd.\", a UK-based online retailer specializing in unique giftware. The analysis follows a structured approach to transform raw transactional data into actionable business insights.\n",
    "\n",
    "## Project Phases:\n",
    "1. **Data Sanitation and Preprocessing** - Cleaning and preparing the data\n",
    "2. **Exploratory Data Analysis** - Uncovering patterns and trends\n",
    "3. **RFM Customer Segmentation** - Advanced customer analytics\n",
    "4. **Strategic Recommendations** - Business insights and strategies\n",
    "5. **Data Enrichment** - API integration for currency conversion\n",
    "\n",
    "## Business Questions Addressed:\n",
    "- Sales performance and seasonality patterns\n",
    "- Product portfolio optimization\n",
    "- Geographic footprint analysis\n",
    "- Customer segmentation\n",
    "- Wholesaler vs. retail customer analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609e692",
   "metadata": {},
   "source": [
    "# Phase 1: Data Sanitation and Preprocessing\n",
    "\n",
    "In this phase, we clean and prepare the raw dataset for analysis by:\n",
    "- Handling missing values and duplicates\n",
    "- Removing cancelled orders and non-product items\n",
    "- Creating derived features for temporal analysis\n",
    "- Converting data types appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "df = pd.read_csv('../data/raw/online_retail.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nDataset info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "df = df.rename(columns={\n",
    "    'Invoice': 'InvoiceNo',\n",
    "    'Price': 'UnitPrice', \n",
    "    'Customer ID': 'CustomerID',\n",
    "    'InvoiceDate': 'InvoiceDate'\n",
    "})\n",
    "\n",
    "# Remove duplicates\n",
    "print(\"Duplicate count before:\", df.duplicated().sum())\n",
    "df = df.drop_duplicates()\n",
    "print(\"Duplicate count after:\", df.duplicated().sum())\n",
    "\n",
    "# Handle cancelled orders (InvoiceNo starting with 'C')\n",
    "df['InvoiceNo'] = df['InvoiceNo'].astype(str)\n",
    "cancel_mask = df['InvoiceNo'].str.startswith('C', na=False)\n",
    "cancelled = df[cancel_mask].copy()\n",
    "df = df[~cancel_mask]\n",
    "print(f\"Removed {len(cancelled)} cancelled orders\")\n",
    "\n",
    "# Remove rows with non-positive quantity or price\n",
    "non_pos_mask = (df['Quantity'] <= 0) | (df['UnitPrice'] <= 0)\n",
    "non_pos_rows = df[non_pos_mask].copy()\n",
    "df = df[~non_pos_mask]\n",
    "print(f\"Removed {len(non_pos_rows)} rows with non-positive quantity/price\")\n",
    "\n",
    "# Filter out non-product items (postage, adjustments, etc.)\n",
    "non_product_pattern = r'POST|POSTAGE|ADJUST|BANK|M|CARR|DOT'\n",
    "mask_nonprod = df['StockCode'].astype(str).str.contains(non_product_pattern, case=False, na=False)\n",
    "non_prod_rows = df[mask_nonprod].copy()\n",
    "df = df[~mask_nonprod]\n",
    "print(f\"Removed {len(non_prod_rows)} non-product rows\")\n",
    "\n",
    "# Create TotalPrice column\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Convert InvoiceDate to datetime and extract temporal features\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], dayfirst=True, errors='coerce')\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "\n",
    "# Handle missing CustomerID - create separate dataset for RFM analysis\n",
    "print(f\"Missing CustomerID before: {df['CustomerID'].isnull().sum()}\")\n",
    "df_with_cust = df.dropna(subset=['CustomerID']).copy()\n",
    "df_with_cust['CustomerID'] = df_with_cust['CustomerID'].astype(int)\n",
    "print(f\"Missing CustomerID after: {df_with_cust['CustomerID'].isnull().sum()}\")\n",
    "\n",
    "# Save cleaned datasets\n",
    "df.to_csv('../data/processed/online_retail_clean.csv', index=False)\n",
    "df_with_cust.to_csv('../data/processed/online_retail_clean_with_customerids.csv', index=False)\n",
    "\n",
    "print(\"Phase 1 completed. Cleaned datasets saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0619fb3b",
   "metadata": {},
   "source": [
    "# Phase 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this phase, we explore the cleaned data to uncover patterns, trends, and insights that answer the business questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9babcf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('../data/processed/online_retail_clean.csv')\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Display basic information about cleaned data\n",
    "print(\"Cleaned dataset shape:\", df.shape)\n",
    "print(\"\\nBasic statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Quantity distribution\n",
    "sns.histplot(df['Quantity'], bins=50, kde=False, ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of Quantity\")\n",
    "axes[0].set_xlim(0, df['Quantity'].quantile(0.99))  # Remove extreme outliers\n",
    "\n",
    "# UnitPrice distribution\n",
    "sns.histplot(df['UnitPrice'], bins=50, kde=False, ax=axes[1])\n",
    "axes[1].set_title(\"Distribution of Unit Price\")\n",
    "axes[1].set_xlim(0, df['UnitPrice'].quantile(0.99))  # Remove extreme outliers\n",
    "\n",
    "# TotalPrice distribution\n",
    "sns.histplot(df['TotalPrice'], bins=50, kde=False, ax=axes[2])\n",
    "axes[2].set_title(\"Distribution of Total Price\")\n",
    "axes[2].set_xlim(0, df['TotalPrice'].quantile(0.99))  # Remove extreme outliers\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal analysis - Monthly sales trend\n",
    "monthly_sales = df.groupby(['Year', 'Month'])['TotalPrice'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.lineplot(data=monthly_sales, x='Month', y='TotalPrice', hue='Year', marker='o')\n",
    "plt.title(\"Monthly Sales Trend (2010-2011)\")\n",
    "plt.ylabel(\"Total Revenue (£)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by day of week\n",
    "dow_sales = df.groupby('DayOfWeek')['TotalPrice'].sum().reset_index()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_sales['DayOfWeek'] = pd.Categorical(dow_sales['DayOfWeek'], categories=day_order, ordered=True)\n",
    "dow_sales = dow_sales.sort_values('DayOfWeek')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=dow_sales, x='DayOfWeek', y='TotalPrice')\n",
    "plt.title(\"Sales by Day of Week\")\n",
    "plt.ylabel(\"Total Revenue (£)\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic analysis - Top countries by revenue\n",
    "country_sales = df.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False).reset_index()\n",
    "top_10_countries = country_sales.head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=top_10_countries, x='TotalPrice', y='Country')\n",
    "plt.title(\"Top 10 Countries by Revenue\")\n",
    "plt.xlabel(\"Total Revenue (£)\")\n",
    "plt.ylabel(\"Country\")\n",
    "plt.show()\n",
    "\n",
    "# UK vs International revenue\n",
    "uk_revenue = country_sales[country_sales['Country'] == 'United Kingdom']['TotalPrice'].values[0]\n",
    "intl_revenue = country_sales[country_sales['Country'] != 'United Kingdom']['TotalPrice'].sum()\n",
    "total_revenue = uk_revenue + intl_revenue\n",
    "\n",
    "print(f\"UK Revenue: £{uk_revenue:,.2f} ({uk_revenue/total_revenue*100:.1f}%)\")\n",
    "print(f\"International Revenue: £{intl_revenue:,.2f} ({intl_revenue/total_revenue*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product performance analysis\n",
    "# Top 10 products by quantity sold\n",
    "top_products_qty = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Top 10 products by revenue\n",
    "top_products_rev = df.groupby('Description')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
    "\n",
    "# Create comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "sns.barplot(x=top_products_qty.values, y=top_products_qty.index, ax=axes[0])\n",
    "axes[0].set_title(\"Top 10 Products by Quantity Sold\")\n",
    "axes[0].set_xlabel(\"Total Quantity Sold\")\n",
    "\n",
    "sns.barplot(x=top_products_rev.values, y=top_products_rev.index, ax=axes[1])\n",
    "axes[1].set_title(\"Top 10 Products by Revenue\")\n",
    "axes[1].set_xlabel(\"Total Revenue (£)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c577702",
   "metadata": {},
   "source": [
    "# Phase 3: RFM Customer Segmentation\n",
    "\n",
    "In this phase, we implement the RFM (Recency, Frequency, Monetary) model to segment customers based on their purchasing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5105bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with CustomerIDs for RFM analysis\n",
    "df_rfm = pd.read_csv('online_retail_clean_with_customerids.csv')\n",
    "df_rfm['InvoiceDate'] = pd.to_datetime(df_rfm['InvoiceDate'])\n",
    "\n",
    "# Calculate RFM metrics\n",
    "snapshot_date = df_rfm['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "rfm = df_rfm.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency\n",
    "    'InvoiceNo': 'nunique',                                  # Frequency\n",
    "    'TotalPrice': 'sum'                                      # Monetary\n",
    "}).reset_index()\n",
    "\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "rfm = rfm.dropna()\n",
    "\n",
    "print(\"RFM metrics calculated for\", len(rfm), \"customers\")\n",
    "rfm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129c26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFM scores using quintiles\n",
    "# For Recency: lower values are better (score 5 = most recent)\n",
    "rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])\n",
    "\n",
    "# For Frequency and Monetary: higher values are better (score 5 = highest)\n",
    "rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5])\n",
    "rfm['M_Score'] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Create combined RFM segment\n",
    "rfm['RFM_Segment'] = rfm['R_Score'].astype(str) + rfm['F_Score'].astype(str) + rfm['M_Score'].astype(str)\n",
    "rfm['RFM_Score'] = rfm[['R_Score', 'F_Score', 'M_Score']].astype(int).sum(axis=1)\n",
    "\n",
    "# Map to descriptive segments using the refined function\n",
    "def label_segment(row):\n",
    "    r, f, m = row['R_Score'], row['F_Score'], row['M_Score']\n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    elif f >= 4 and (r >= 3 or m >= 3):\n",
    "        return 'Loyal Customers'\n",
    "    elif r >= 4 and (f == 3 or m == 3):\n",
    "        return 'Potential Loyalists'\n",
    "    elif r >= 4 and f <= 2 and m <= 2:\n",
    "        return 'New Customers'\n",
    "    elif r <= 2 and (f >= 4 or m >= 4):\n",
    "        return 'At-Risk'\n",
    "    else:\n",
    "        return 'Hibernating'\n",
    "\n",
    "rfm['Segment'] = rfm.apply(label_segment, axis=1)\n",
    "\n",
    "# Display segment distribution\n",
    "segment_counts = rfm['Segment'].value_counts()\n",
    "print(\"Customer segments with refined labeling:\")\n",
    "print(segment_counts)\n",
    "\n",
    "# Visualization: Segment Size (Counts)\n",
    "plt.figure(figsize=(10, 6))\n",
    "segment_counts.plot(kind='bar')\n",
    "plt.title(\"Customer Segments by Count\")\n",
    "plt.xlabel(\"Segment\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Monetary Distribution (Log Scale)\n",
    "mon = rfm['Monetary'].clip(lower=0.01)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log10(mon), bins=40, edgecolor='black', alpha=0.7)\n",
    "plt.title(\"Customer Monetary Value Distribution (log10 scale)\")\n",
    "plt.xlabel(\"log10(Monetary £)\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Add analysis of the monetary distribution\n",
    "print(f\"Mean customer monetary value: £{rfm['Monetary'].mean():,.2f}\")\n",
    "print(f\"Median customer monetary value: £{rfm['Monetary'].median():,.2f}\")\n",
    "print(f\"Top 10% of customers account for {rfm['Monetary'].quantile(0.9) / rfm['Monetary'].sum() * 100:.1f}% of revenue\")\n",
    "\n",
    "# Save RFM results\n",
    "rfm.to_csv('rfm_segments.csv', index=False)\n",
    "print(\"RFM segmentation saved to rfm_segments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176122f",
   "metadata": {},
   "source": [
    "# Phase 4: Strategic Recommendations\n",
    "\n",
    "In this phase, we analyze the RFM segments and investigate the wholesaler hypothesis to provide actionable business recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze customer spending to identify wholesalers\n",
    "customer_spend = df_rfm.groupby('CustomerID')['TotalPrice'].sum()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(customer_spend, bins=100, kde=True)\n",
    "plt.xlim(0, 10000)  # Zoom in on most customers\n",
    "plt.title(\"Distribution of Customer Spend (£)\")\n",
    "plt.xlabel(\"Total Spend\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()\n",
    "\n",
    "# Identify wholesalers (threshold: £5000)\n",
    "wholesaler_threshold = 5000\n",
    "wholesalers = customer_spend[customer_spend > wholesaler_threshold]\n",
    "retail_customers = customer_spend[customer_spend <= wholesaler_threshold]\n",
    "\n",
    "print(f\"Wholesalers (spend > £{wholesaler_threshold}): {len(wholesalers)} customers\")\n",
    "print(f\"Retail customers: {len(retail_customers)} customers\")\n",
    "\n",
    "# Merge spend data with RFM segments\n",
    "rfm_with_spend = rfm.merge(customer_spend.rename(\"TotalSpend\"), on=\"CustomerID\")\n",
    "rfm_with_spend['CustomerType'] = rfm_with_spend['TotalSpend'].apply(\n",
    "    lambda x: 'Wholesaler' if x > wholesaler_threshold else 'Retail'\n",
    ")\n",
    "\n",
    "# Compare behavior between wholesalers and retail customers\n",
    "behavior_summary = rfm_with_spend.groupby('CustomerType').agg({\n",
    "    'Monetary': 'mean',\n",
    "    'Frequency': 'mean', \n",
    "    'Recency': 'mean',\n",
    "    'CustomerID': 'count'\n",
    "}).rename(columns={\n",
    "    'Monetary': 'Avg_Spend',\n",
    "    'Frequency': 'Avg_Orders',\n",
    "    'Recency': 'Avg_Recency_Days',\n",
    "    'CustomerID': 'Count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Behavior comparison:\")\n",
    "print(behavior_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500356ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize customer types\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=rfm_with_spend, x='CustomerType', order=['Retail', 'Wholesaler'])\n",
    "plt.title(\"Retail vs Wholesaler Customer Count\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()\n",
    "\n",
    "# Analyze segments by customer type\n",
    "segment_by_type = pd.crosstab(rfm_with_spend['Segment'], rfm_with_spend['CustomerType'])\n",
    "segment_by_type['Total'] = segment_by_type.sum(axis=1)\n",
    "segment_by_type = segment_by_type.sort_values('Total', ascending=False)\n",
    "\n",
    "print(\"Segment distribution by customer type:\")\n",
    "print(segment_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd298089",
   "metadata": {},
   "source": [
    "# Phase 5: Data Enrichment via API Integration\n",
    "\n",
    "In this phase, we integrate external data through API calls to enrich our dataset with currency conversion information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f562405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 100 transactions by revenue\n",
    "top_100 = df.sort_values('TotalPrice', ascending=False).head(100).copy()\n",
    "\n",
    "# Fetch exchange rates from API\n",
    "api_url = \"https://api.exchangerate-api.com/v4/latest/GBP\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        rates = response.json()['rates']\n",
    "        gbp_to_usd = rates['USD']\n",
    "        gbp_to_eur = rates['EUR']\n",
    "        \n",
    "        print(f\"GBP to USD rate: {gbp_to_usd}\")\n",
    "        print(f\"GBP to EUR rate: {gbp_to_eur}\")\n",
    "        \n",
    "        # Add converted price columns\n",
    "        top_100['TotalPrice_USD'] = top_100['TotalPrice'] * gbp_to_usd\n",
    "        top_100['TotalPrice_EUR'] = top_100['TotalPrice'] * gbp_to_eur\n",
    "        \n",
    "        # Display results\n",
    "        print(\"\\nTop 5 transactions with currency conversion:\")\n",
    "        display(top_100[['InvoiceNo', 'TotalPrice', 'TotalPrice_USD', 'TotalPrice_EUR']].head())\n",
    "        \n",
    "        # Save enriched data\n",
    "        top_100.to_csv('../data/processed/top_100_transactions_enriched.csv', index=False)\n",
    "        print(\"\\nEnriched data saved to top_100_transactions_enriched.csv\")\n",
    "    else:\n",
    "        print(f\"API request failed with status code: {response.status_code}\")\n",
    "        # Use fallback rates if API fails\n",
    "        gbp_to_usd = 1.3\n",
    "        gbp_to_eur = 1.17\n",
    "        print(\"Using fallback exchange rates\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching exchange rates: {e}\")\n",
    "    # Use fallback rates\n",
    "    gbp_to_usd = 1.3\n",
    "    gbp_to_eur = 1.17\n",
    "    print(\"Using fallback exchange rates\")\n",
    "\n",
    "# Visualize top transactions in different currencies\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.barplot(data=top_100.head(10), x='TotalPrice', y='Description')\n",
    "plt.title(\"Top 10 Transactions (GBP)\")\n",
    "plt.xlabel(\"Value (£)\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.barplot(data=top_100.head(10), x='TotalPrice_USD', y='Description')\n",
    "plt.title(\"Top 10 Transactions (USD)\")\n",
    "plt.xlabel(\"Value ($)\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(data=top_100.head(10), x='TotalPrice_EUR', y='Description')\n",
    "plt.title(\"Top 10 Transactions (EUR)\")\n",
    "plt.xlabel(\"Value (€)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91cfb7e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This comprehensive analysis has provided valuable insights into Unique Gifts Ltd.'s business operations. Key findings include:\n",
    "\n",
    "## Sales Performance:\n",
    "- Clear seasonal patterns with peaks in November/December (holiday season)\n",
    "- Thursday is the highest revenue day of the week\n",
    "- UK market dominates (85%+ of revenue) with significant international opportunities\n",
    "\n",
    "## Product Portfolio:\n",
    "- Different products rank differently by quantity vs. revenue\n",
    "- Both high-volume \"bread-and-butter\" and high-value \"cash cow\" products identified\n",
    "\n",
    "## Customer Segmentation:\n",
    "- RFM analysis identified distinct customer segments (Champions, Loyal Customers, etc.)\n",
    "- Wholesalers represent a small but significant portion of high-value customers\n",
    "- The monetary value distribution shows a long tail with a small number of customers contributing disproportionately to revenue\n",
    "\n",
    "## Strategic Recommendations:\n",
    "1. **Targeted Marketing**: Develop segment-specific campaigns\n",
    "2. **Inventory Optimization**: Align stock with seasonal patterns and product performance\n",
    "3. **International Expansion**: Focus on top international markets\n",
    "4. **Wholesaler Strategy**: Develop dedicated account management for high-value wholesalers\n",
    "5. **Pricing Strategy**: Consider regional pricing based on currency analysis\n",
    "\n",
    "The data enrichment via API integration demonstrates the value of incorporating external data for international business decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final notebook outputs\n",
    "outputs = {\n",
    "    'monthly_sales': monthly_sales,\n",
    "    'country_sales': country_sales,\n",
    "    'top_products_qty': top_products_qty,\n",
    "    'top_products_rev': top_products_rev,\n",
    "    'rfm_segments': rfm,\n",
    "    'wholesaler_analysis': behavior_summary\n",
    "}\n",
    "\n",
    "# Create outputs directory\n",
    "Path('../data/outputs').mkdir(exist_ok=True)\n",
    "\n",
    "# Save each output\n",
    "for name, data in outputs.items():\n",
    "    if hasattr(data, 'to_csv'):\n",
    "        data.to_csv(f'../data/outputs/{name}.csv', index=False)\n",
    "    else:\n",
    "        pd.DataFrame(data).to_csv(f'../data/outputs/{name}.csv', index=False)\n",
    "\n",
    "print(\"All analysis outputs saved to outputs/ directory\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
